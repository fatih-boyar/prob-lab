---
title: "About"
bibliography: references.bib
image: canyon2.jpeg
about:
  template: marquee

---

Most published research findings are false [@Ioannidis2005]. 
Unfortunately, the main reason isn't a few "bad apples" engaging in p-hacking, data fabrication, or other fraudulent practices. 
Rather, it is due to a form of statistical blindness; specifically, the mechanical application of frequentist methods like significance testing simply because they are the industry standard.

Since the early 2010s, we have indeed witnessed a massive issue known as the *Replication Crisis*. 
Many cornerstone studies, ranging from the social sciences to medicine, failed to replicate because they all followed the same rigid rules of statistical testing. 
Yet, we seem to keep applying temporary patches, such as lowering the acceptance threshold for p-values to 0.01.

The bridge out of this mess is actually rethinking probability at a fundamental level. 
It is a painful realization, mostly because it forces us to go back to the start while everyone else is still busy fighting over methodologies. 
But really, it just returns us to the perspective E.T. Jaynes pointed out: probability is not a tool *for* science, but the logic *of* science [@jaynes2003probability]. 
This isn't something we can neglect, especially in the social sciences where statistical packages are too often treated like push-button appliances.

So, I decided to save the world (as every PhD student attempts to do) or die trying (which means overall, publishing a few papers).
Bernoulli's Fallacy by Aubrey Clayton [-@clayton2021bernoulli] greatly helped me put the pieces together. This blog documents my journey of following the Clayton's steps, re-learning probability, running simulations, and building applets, along with some personal reflections.

::: {.small}
The photo on this page is a gift from my dear friend [(link to the ig page)](https://www.instagram.com/ira.lume/)
:::
